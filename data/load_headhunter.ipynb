{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url_main = 'https://api.hh.ru/vacancies'\n",
    "param = \"?\"\n",
    "hosts = [\"host=hh.ua\", \"host=hh.ru\", \"host=career.ru\", \"host=jobs.tut.by\",\n",
    "        \"host=jobs.day.az\", \"host=hh.uz\", \"host=hh.kz\", \"host=headhunter.ge\",\n",
    "       \"host=headhunter.kg\"]\n",
    "an = \"&\"\n",
    "per_p = \"per_page=\"\n",
    "page = \"page=\"\n",
    "url =  'https://api.hh.ru/vacancies?host=hh.ua&per_page=100&page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get('https://api.hh.ru/vacancies?host=hh.ua&per_page=100&page=0')\n",
    "print(r.status_code)\n",
    "#print(r.text)\n",
    "#vacancies = json.loads(r.text)\n",
    "#print(json.loads(r.text)[\"items\"][0])\n",
    "#print()\n",
    "#print(json.loads(r.text)[\"items\"][0][\"snippet\"])\n",
    "len(json.loads(r.text)[\"items\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_vacancies_ids(url, hosts):\n",
    "    vacancies = []\n",
    "    vac_ids = []\n",
    "    param = \"?\"\n",
    "    an = \"&\"\n",
    "    per_page = \"per_page=100\"\n",
    "    page = \"page=\"\n",
    "    for host in hosts:\n",
    "        for i in range(20):\n",
    "            url_mod = url + param + host\n",
    "            url_mod = url_mod + an + per_page + an + page + str(i)\n",
    "            r = requests.get(url_mod)\n",
    "            vac = json.loads(r.text)\n",
    "            vacancies = vacancies + vac[\"items\"]\n",
    "            vac_ids = vac_ids + [i[\"id\"] for i in vac[\"items\"]]\n",
    "    return vac_ids, vacancies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vac_ids, vacancies = load_vacancies_ids(url_main, hosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vac_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_set = set(vac_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3815"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25978699'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ids_set)[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"headHunter_data/hh_ids.dat\", \"rb\") as inf:\n",
    "    ids2_list = pickle.load(inf)\n",
    "    \n",
    "with open(\"headHunter_data/hh_vacancies.dat\", \"rb\") as inf:\n",
    "    vacancies2 = pickle.load(inf)\n",
    "    \n",
    "with open(\"headHunter_data/hh_vacancies_ext.dat\", \"rb\") as inf:\n",
    "    vacancies_ext2 = pickle.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14913\n",
      "14372\n",
      "18187\n",
      "16487\n"
     ]
    }
   ],
   "source": [
    "print(len(vacancies_ext2))\n",
    "print(len(ids2_list))\n",
    "print(len(ids2_list + list(ids_set)))\n",
    "\n",
    "ids_all = set(ids2_list + list(ids_set))\n",
    "\n",
    "print(len(ids_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1700"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids_set.intersection(set(ids2_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2115\n"
     ]
    }
   ],
   "source": [
    "unic_ids = ids_set.difference(ids_set.intersection(set(ids2_list)))\n",
    "print(len(unic_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n"
     ]
    }
   ],
   "source": [
    "vacancies = vacancies2 + vacancies\n",
    "print(len(vacancies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16487\n"
     ]
    }
   ],
   "source": [
    "ids_all = set(ids2_list + list(unic_ids))\n",
    "print(len(ids_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hh_ids.dat\", \"wb\") as ouf:\n",
    "    pickle.dump(list(ids_all), ouf)\n",
    "    \n",
    "with open(\"hh_vacancies.dat\", \"wb\") as ouf:\n",
    "    pickle.dump(vacancies, ouf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_vacancies_extended(url, ids):\n",
    "    vacancies_ext = []\n",
    "    count = 0\n",
    "    for i in ids:\n",
    "        url_mod = url + \"/\" + str(i)\n",
    "        r = requests.get(url_mod)\n",
    "        vacancy = json.loads(r.text)\n",
    "        vacancies_ext.append(vacancy)\n",
    "        count += 1\n",
    "        \n",
    "        if count % 500 == 0:\n",
    "            print(count)\n",
    "    return vacancies_ext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "Wall time: 8min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vacancies_ext = load_vacancies_extended(url_main, list(unic_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2115\n",
      "14913\n"
     ]
    }
   ],
   "source": [
    "print(len(vacancies_ext))\n",
    "print(len(vacancies_ext2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17028\n"
     ]
    }
   ],
   "source": [
    "vacancies_ext = vacancies_ext2 + vacancies_ext\n",
    "print(len(vacancies_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hh_vacancies_ext.dat\", \"wb\") as ouf:\n",
    "    pickle.dump(list(vacancies_ext), ouf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"hh_ids.json\", \"w\") as ouf:\n",
    "    json.dump(list(ids_all), ouf, ensure_ascii=False)\n",
    "    \n",
    "with open(\"hh_vacancies.json\", \"w\") as ouf:\n",
    "    json.dump(vacancies, ouf, ensure_ascii=False)\n",
    "    \n",
    "with open(\"hh_vacancies_ext.json\", \"w\") as ouf:\n",
    "    json.dump(vacancies_ext, ouf, ensure_ascii=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hh_ids.json\", \"w\") as ouf:\n",
    "    json.dump(list(ids_all), ouf, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(vacancies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"headHunter_data/hh_vacancies.dat\", \"rb\") as inf:\n",
    "    t = pickle.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11112"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"headHunter_data/hh_vacancies_ext.dat\", \"rb\") as inf:\n",
    "    t = pickle.load(inf)\n",
    "len(t)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11061"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"headHunter_data/hh_ids.dat\", \"rb\") as inf:\n",
    "    t = pickle.load(inf)\n",
    "len(t)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16487\n",
      "90000\n",
      "17028\n"
     ]
    }
   ],
   "source": [
    "with open(\"hh_ids.dat\", \"rb\") as inf:\n",
    "    t = pickle.load(inf)\n",
    "print(len(t))\n",
    "\n",
    "with open(\"hh_vacancies.dat\", \"rb\") as inf:\n",
    "    t = pickle.load(inf)\n",
    "print(len(t))\n",
    "\n",
    "with open(\"hh_vacancies_ext.dat\", \"rb\") as inf:\n",
    "    t = pickle.load(inf)\n",
    "print(len(t))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
