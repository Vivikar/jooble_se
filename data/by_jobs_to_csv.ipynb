{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import config\n",
    "\n",
    "data_path = os.path.join(\"by_jobs\")\n",
    "text_processing_url = config.text_processing_url\n",
    "n_vacancies_to_save = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    \"\"\"\n",
    "    Load all data to pandas.DataFrame\n",
    "    \n",
    "    :param str data_path: Path to folder with data \n",
    "    :return pd.DataFrame data:\n",
    "    \"\"\"\n",
    "    docs_info = []\n",
    "    docs_text = []\n",
    "    file_names = os.listdir(data_path)\n",
    "\n",
    "    for file in file_names:\n",
    "        if \"text\" in file:\n",
    "            with gzip.open(os.path.join(data_path, file), \"rb\") as f:\n",
    "                for line in f:\n",
    "                    vacancy = json.loads(line)\n",
    "                    docs_text.append(vacancy)\n",
    "        else:\n",
    "            with gzip.open(os.path.join(data_path, file), \"rb\") as inf:\n",
    "                for line in inf:\n",
    "                    vacancy = json.loads(line)\n",
    "                    docs_info.append(vacancy)\n",
    "\n",
    "    assert len(docs_info) == len(docs_text)\n",
    "    assert \"id\" in docs_info[0].keys()\n",
    "    assert \"id_job\" in docs_text[0].keys()\n",
    "\n",
    "    docs_info = pd.DataFrame(docs_info)\n",
    "    docs_text = pd.DataFrame(docs_text)\n",
    "    docs_info.drop_duplicates([\"id\"], inplace=True)\n",
    "    docs_text.drop_duplicates([\"id_job\"], inplace=True)\n",
    "    data = docs_info.merge(docs_text, left_on='id', right_on='id_job', how='outer')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = load_data(data_path)\n",
    "print(len(full_df))\n",
    "#full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(\"by_jobs_full.csv\", sep='\\t', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nessesary_df = full_df.reindex(columns=[\"id\", \"title\",\n",
    "                                        \"lang_title\",\n",
    "                                        \"title_normalized\",\n",
    "                                        \"text\", \n",
    "                                        \"lang_text\",\n",
    "                                        \"text_normalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize text and title using text_preprocessing service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for index, row in nessesary_df.loc[:n_vacancies_to_save].iterrows():\n",
    "    title = row[\"title\"]\n",
    "    text = row[\"text\"]\n",
    "    r = requests.post(text_processing_url + config.STEM_TEXT_PATH,\n",
    "                          json=text)\n",
    "    nessesary_df.loc[index, [\"text_normalized\"]] = r.text\n",
    "    \n",
    "    r = requests.post(text_processing_url + config.STEM_TEXT_PATH,\n",
    "                          json=title)\n",
    "    nessesary_df.loc[index, [\"title_normalized\"]] = r.text\n",
    "    \n",
    "    if index % 500 == 0:\n",
    "        print(index)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nessesary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nessesary_df.to_csv(\"by_jobs.csv\", sep='\\t', header=True, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
